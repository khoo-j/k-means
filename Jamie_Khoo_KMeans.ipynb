{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Jamie_Khoo-KMeans.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "transsexual-stations"
      },
      "source": [
        "##### Dependencies\n",
        "\n",
        "This notebook requires sklearn, pandas, and numpy"
      ],
      "id": "transsexual-stations"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "approved-permission"
      },
      "source": [
        "# Exercise\n",
        "\n",
        "Objective: Create a program to identify images of 10 handwritten digits in the digit dataset. This is a classification exercise.\n",
        "\n",
        "\n",
        "Caveat: One will need to run K-means **without** using any machine learning packages. K-means from scratch.\n",
        "\n",
        "## Approach:\n",
        "\n",
        "1. Come up with a set of clusters where distance between clusters is large & distance between points within a cluster is small\n",
        "\n",
        "2. Represent each cluster with a single vector called a 'centroid'\n",
        "\n",
        "3. Minimize the sum of distances between points & centers of their assigned clusters\n",
        "\n",
        "## Steps:\n",
        "\n",
        "1. Randomly initialize k-number of centroids\n",
        "\n",
        "2. Assign each point to the closest centroid: argmin of L2 norm\n",
        "\n",
        "3. Update the centroids: For each cluster, calculate the mean of all data points assigned to the cluster.\n",
        "\n",
        "4. Based on the new centroids, assign each point to the closest (new centroids), essentially: iterate over steps 2 & 3"
      ],
      "id": "approved-permission"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MviXMN-nJBI4"
      },
      "source": [
        "# If needed: Install the latest sklearn package\n",
        "\n",
        "#!pip install --upgrade scikit-learn"
      ],
      "id": "MviXMN-nJBI4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sealed-intent"
      },
      "source": [
        "from sklearn.datasets import load_digits\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "id": "sealed-intent",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "capital-belgium"
      },
      "source": [
        "def cluster_loss(x,centroids):\n",
        "    '''\n",
        "    Single-vector L2 Loss function for k-means\n",
        "    \n",
        "    Params: \n",
        "    x is a dataframe of a single point that correspond to a given cluster\n",
        "    centroids is a dataframe for all possible k numbers of centroids\n",
        "    \n",
        "    Returns:\n",
        "    A tuple of the class label of the centroid closest to the datapoint \n",
        "    and its loss squared value = (x- closest centroid)^2\n",
        "    '''\n",
        "    loss = []\n",
        "    \n",
        "    for index, row in centroids.iterrows():\n",
        "        dis = ((x - row)**2).sum()\n",
        "        loss.append(dis)\n",
        "        \n",
        "    mLoss = min(loss)\n",
        "    mLossInd = loss.index(mLoss)\n",
        "    return (mLoss, mLossInd)\n",
        "\n",
        "def update_clusters(x):\n",
        "    '''\n",
        "    Updates cluster centers to be mean of all points assigned to the cluster\n",
        "    \n",
        "    Params:\n",
        "    X is a dataframe of clustered data points, whereby cluster assignment is contained inside 'cluster_assignment' column\n",
        "    \n",
        "    Returns:\n",
        "    A dataframe of new centroid points, which really are the mean of all data points in a given cluster\n",
        "    '''\n",
        "    new_centroids = x.groupby('cluster_assignment',as_index=False).mean()\n",
        "    new_centroids = new_centroids.drop(columns=['cluster_assignment','cluster_loss_sq'])\n",
        "    return (new_centroids)"
      ],
      "id": "capital-belgium",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "remarkable-advisory"
      },
      "source": [
        "# Dataset of 10 handwritten digits (10 classes), with 64 dimensions\n",
        "\n",
        "ld = load_digits(as_frame=True)\n",
        "\n",
        "x_df = pd.DataFrame(ld.data, columns=ld.feature_names)"
      ],
      "id": "remarkable-advisory",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "stylish-armstrong"
      },
      "source": [
        "# Initiate epoch-loss tracker for plotting later\n",
        "epoch_loss_tracker_15 = pd.DataFrame(columns=[\"Epoch\",\"SSE\"])\n",
        "epoch_loss_tracker_15 = epoch_loss_tracker_15.append({'Epoch':0, 'SSE': 0}, ignore_index=True) #Placeholder hack for while loop to work\n",
        "\n",
        "# Step 1: Randomly initiate centroids. Control number of 'k' via parameter after \"size=\"\n",
        "initiate_cent = pd.DataFrame(np.random.randint(0,16, size=(15, len(ld.feature_names))), columns=ld.feature_names)\n",
        "\n",
        "# Step 2: Assign each data point to the closest centroid and calculate euclidean distance squared to respective centroids\n",
        "x_df['cluster_loss_sq'] = x_df.apply(lambda row: cluster_loss(row, initiate_cent), axis=1)\n",
        "x_df['cluster_loss_sq'], x_df['cluster_assignment'] = zip(*x_df['cluster_loss_sq'])\n",
        "epoch_loss_tracker_15 = epoch_loss_tracker_15.append({'Epoch':1, 'SSE': round(x_df['cluster_loss_sq'].sum(),9)}, ignore_index=True)\n",
        "ld_df = update_clusters(x_df)\n",
        "x_df = x_df.drop(columns=['cluster_assignment','cluster_loss_sq'])\n",
        "\n",
        "# Step 3: Iterate until SSE no longer improves (accurate to the 2nd decimal point)\n",
        "step = 2\n",
        "\n",
        "while epoch_loss_tracker_15.iloc[-1, 1] != epoch_loss_tracker_15.iloc[-2, 1]:\n",
        "    x_df['cluster_loss_sq'] = x_df.apply(lambda row: cluster_loss(row, ld_df), axis=1)\n",
        "    x_df['cluster_loss_sq'], x_df['cluster_assignment'] = zip(*x_df['cluster_loss_sq'])\n",
        "    epoch_loss_tracker_15 = epoch_loss_tracker_15.append({'Epoch':step, 'SSE': round(x_df['cluster_loss_sq'].sum(),9)}, ignore_index=True)\n",
        "    ld_df = update_clusters(x_df)\n",
        "    x_df = x_df.drop(columns=['cluster_assignment','cluster_loss_sq'])\n",
        "    step += 1"
      ],
      "id": "stylish-armstrong",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "satellite-medication"
      },
      "source": [
        "# I ran the block above 3 times, each time for k= 5, k=10, and k = 15 respectively\n",
        "# Loss values are stored as \"epoch_loss_tracker_5\", \"epoch_loss_tracker_10\", and \"epoch_loss_tracker_15\"\n",
        "# We will merge these loss values and plot them in one chart\n",
        "\n",
        "loss = pd.merge(epoch_loss_tracker_5, epoch_loss_tracker_10, on=\"Epoch\", how = 'outer')\n",
        "\n",
        "loss = pd.merge(loss, epoch_loss_tracker_15, on=\"Epoch\", how = 'outer')\n",
        "\n",
        "loss.rename(columns={\"SSE_x\": \"k = 5\", \"SSE_y\": \"k = 10\",\n",
        "                    \"SSE\":\"k = 15\"}, inplace=True)\n",
        "\n",
        "loss = loss.set_index('Epoch')\n",
        "\n",
        "loss = loss.iloc[1:] #delete placeholder row"
      ],
      "id": "satellite-medication",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "indian-illness",
        "outputId": "d8444105-5e6f-49ff-d1d2-23af3b2f4fed"
      },
      "source": [
        "loss.plot()"
      ],
      "id": "indian-illness",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f923d6f3bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "operating-prince",
        "outputId": "4e222914-e70b-4562-c890-da0b70955d63"
      },
      "source": [
        "# Observe the actual loss values below\n",
        "\n",
        "loss"
      ],
      "id": "operating-prince",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>k = 5</th>\n",
              "      <th>k = 10</th>\n",
              "      <th>k = 15</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1.0</th>\n",
              "      <td>5.68612e+06</td>\n",
              "      <td>6.28376e+06</td>\n",
              "      <td>5.55209e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.0</th>\n",
              "      <td>1.85776e+06</td>\n",
              "      <td>1.57757e+06</td>\n",
              "      <td>1.66205e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3.0</th>\n",
              "      <td>1.7854e+06</td>\n",
              "      <td>1.37907e+06</td>\n",
              "      <td>1.44316e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4.0</th>\n",
              "      <td>1.75259e+06</td>\n",
              "      <td>1.27265e+06</td>\n",
              "      <td>1.36703e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5.0</th>\n",
              "      <td>1.72638e+06</td>\n",
              "      <td>1.21493e+06</td>\n",
              "      <td>1.33562e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6.0</th>\n",
              "      <td>1.70927e+06</td>\n",
              "      <td>1.1941e+06</td>\n",
              "      <td>1.3147e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7.0</th>\n",
              "      <td>1.68618e+06</td>\n",
              "      <td>1.18393e+06</td>\n",
              "      <td>1.29039e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8.0</th>\n",
              "      <td>1.66405e+06</td>\n",
              "      <td>1.17498e+06</td>\n",
              "      <td>1.27958e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9.0</th>\n",
              "      <td>1.64851e+06</td>\n",
              "      <td>1.16913e+06</td>\n",
              "      <td>1.27702e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10.0</th>\n",
              "      <td>1.64068e+06</td>\n",
              "      <td>1.1681e+06</td>\n",
              "      <td>1.27612e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11.0</th>\n",
              "      <td>1.6359e+06</td>\n",
              "      <td>1.16798e+06</td>\n",
              "      <td>1.27564e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12.0</th>\n",
              "      <td>1.63206e+06</td>\n",
              "      <td>1.16796e+06</td>\n",
              "      <td>1.27546e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13.0</th>\n",
              "      <td>1.62741e+06</td>\n",
              "      <td>1.16796e+06</td>\n",
              "      <td>1.27537e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14.0</th>\n",
              "      <td>1.62475e+06</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.27525e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15.0</th>\n",
              "      <td>1.62361e+06</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.27486e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16.0</th>\n",
              "      <td>1.62306e+06</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.27463e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17.0</th>\n",
              "      <td>1.62279e+06</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.27447e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18.0</th>\n",
              "      <td>1.62258e+06</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.27433e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19.0</th>\n",
              "      <td>1.62228e+06</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.27419e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20.0</th>\n",
              "      <td>1.62186e+06</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.27395e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21.0</th>\n",
              "      <td>1.62054e+06</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.27378e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22.0</th>\n",
              "      <td>1.61912e+06</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.27347e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23.0</th>\n",
              "      <td>1.61762e+06</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.27331e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24.0</th>\n",
              "      <td>1.61581e+06</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.27325e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25.0</th>\n",
              "      <td>1.61479e+06</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.27323e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26.0</th>\n",
              "      <td>1.61453e+06</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.27321e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27.0</th>\n",
              "      <td>1.61446e+06</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.27312e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28.0</th>\n",
              "      <td>1.61445e+06</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.2728e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29.0</th>\n",
              "      <td>1.61445e+06</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.27254e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30.0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.27231e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31.0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.27224e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32.0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.27217e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33.0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.27216e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34.0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.27216e+06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             k = 5       k = 10       k = 15\n",
              "Epoch                                       \n",
              "1.0    5.68612e+06  6.28376e+06  5.55209e+06\n",
              "2.0    1.85776e+06  1.57757e+06  1.66205e+06\n",
              "3.0     1.7854e+06  1.37907e+06  1.44316e+06\n",
              "4.0    1.75259e+06  1.27265e+06  1.36703e+06\n",
              "5.0    1.72638e+06  1.21493e+06  1.33562e+06\n",
              "6.0    1.70927e+06   1.1941e+06   1.3147e+06\n",
              "7.0    1.68618e+06  1.18393e+06  1.29039e+06\n",
              "8.0    1.66405e+06  1.17498e+06  1.27958e+06\n",
              "9.0    1.64851e+06  1.16913e+06  1.27702e+06\n",
              "10.0   1.64068e+06   1.1681e+06  1.27612e+06\n",
              "11.0    1.6359e+06  1.16798e+06  1.27564e+06\n",
              "12.0   1.63206e+06  1.16796e+06  1.27546e+06\n",
              "13.0   1.62741e+06  1.16796e+06  1.27537e+06\n",
              "14.0   1.62475e+06          NaN  1.27525e+06\n",
              "15.0   1.62361e+06          NaN  1.27486e+06\n",
              "16.0   1.62306e+06          NaN  1.27463e+06\n",
              "17.0   1.62279e+06          NaN  1.27447e+06\n",
              "18.0   1.62258e+06          NaN  1.27433e+06\n",
              "19.0   1.62228e+06          NaN  1.27419e+06\n",
              "20.0   1.62186e+06          NaN  1.27395e+06\n",
              "21.0   1.62054e+06          NaN  1.27378e+06\n",
              "22.0   1.61912e+06          NaN  1.27347e+06\n",
              "23.0   1.61762e+06          NaN  1.27331e+06\n",
              "24.0   1.61581e+06          NaN  1.27325e+06\n",
              "25.0   1.61479e+06          NaN  1.27323e+06\n",
              "26.0   1.61453e+06          NaN  1.27321e+06\n",
              "27.0   1.61446e+06          NaN  1.27312e+06\n",
              "28.0   1.61445e+06          NaN   1.2728e+06\n",
              "29.0   1.61445e+06          NaN  1.27254e+06\n",
              "30.0           NaN          NaN  1.27231e+06\n",
              "31.0           NaN          NaN  1.27224e+06\n",
              "32.0           NaN          NaN  1.27217e+06\n",
              "33.0           NaN          NaN  1.27216e+06\n",
              "34.0           NaN          NaN  1.27216e+06"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stuck-question"
      },
      "source": [
        "# Observations\n",
        "\n",
        "The actual dataset is handwritten samples of 10 digits. In theory, the clusters should stand to benefit the most from k = 10 (10 clusters)\n",
        "\n",
        "1. We observe the lowest loss achieved is indeed when k = 10"
      ],
      "id": "stuck-question"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anVgly3CfywR"
      },
      "source": [
        ""
      ],
      "id": "anVgly3CfywR",
      "execution_count": null,
      "outputs": []
    }
  ]
}